{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HN-CQ5jTIkMY"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1f1gGVI-rxcHjA90WEGNvvtSXF1pAxQwg\" alt=\"Fasilkom UI\" width=\"300\"/>\n",
        "\n",
        "CSCM602013 • Statistika dan Probabilitas\n",
        "\n",
        "Semester Gasal 2025/2026\n",
        "\n",
        "Fakultas Ilmu Komputer, Universitas Indonesia\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6MbHlx96BIy"
      },
      "source": [
        "- **Name:** Zhafira Uzma, Neal Guarddin, Ahmad Zein Rasyid Siregar\n",
        "- **NPM:** 2406495451, 2406348282, 2406408395\n",
        "- **Class:** C\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDu7MTOrg3XF"
      },
      "source": [
        "# 🪙 Problem 1: The Coin Toss Game (20 points)\n",
        "\n",
        "Imagine you found a game in the city's carnival. Each player tosses a coin 20 times. Every time the coin lands on heads, they win 1 point. Every tails gives 0 points. After 20 tosses, the total points = the number of heads.\n",
        "\n",
        "**Now here’s the big question:** If thousands of players play this game, how often will each final score (0, 1, 2, …, 20) appear?\n",
        "\n",
        "*Note: This question is the heart of probability: how randomness accumulates when we repeat the same simple action many times.*\n",
        "\n",
        "---\n",
        "\n",
        "## Concepts Used In This Problem\n",
        "\n",
        "* **Bernoulli trial:** a single experiment with only two outcomes (like a coin toss: $head$ or $tail$).\n",
        "* **Binomial distribution:** the theoretical rule that tells us the chance of getting exactly $𝑘$ heads out of $𝑛$ tosses.\n",
        "* **Empirical probability:** probability we estimate by simulating and counting outcomes. For example, if out of $10,000$ players, $2,450$ ended with exactly $10$ heads, we say the empirical probability is $2,450/10,000=0.245$.\n",
        "* **Distribution (a histogram):** a way to see \"which results are common, which are rare.\"\n",
        "* **Law of Large Numbers (LLN):** as the number of players grows, the empirical proportions converge to the true $p$.\n",
        "\n",
        "---\n",
        "\n",
        "## Given\n",
        "\n",
        "The provided code already:\n",
        "\n",
        "1. Simulates 50,000 players with $n=20$ tosses and $p=0.5$, then builds the frequency table and histogram.\n",
        "2. Compares the empirical results with the theoretical Binomial$(n=20, p=0.5)$ probabilities.\n",
        "3. Explores biased coins with $p=0.3$ and $p=0.7$ to observe how the distribution shifts and skews.\n",
        "\n",
        "Use the results and functions from that code to answer the following extended questions.\n",
        "\n",
        "---\n",
        "\n",
        "## Your Tasks\n",
        "\n",
        "1. **Should you play the game (5 pts)?** Suppose you are at that carnival. You found out that the carnival now charges an entry fee $F$ to play the game. If a player gets more than $15$ heads in $20$ tosses from a fair coin (i.e., $p=0.5$), the player wins a prize with value $A$.\n",
        "\n",
        "   * Propose a rational player's decision rule **using expected net value (i.e., expected profit)** to decide whether to play or not.\n",
        "   * Should a rational player join if:\n",
        "\n",
        "     * $F=1$ and $A=100$?\n",
        "     * $F=1$ and $A=200$?\n",
        "     * $F=2$ and $A=100$?\n",
        "     * $F=2$ and $A=200$?\n",
        "\n",
        "2. **Analyze the distribution shape (10 pts):**\n",
        "   Using the plots and values from the simulation:\n",
        "\n",
        "   * Describe whether the Binomial$(20, 0.5)$ distribution appears symmetric or skewed.\n",
        "   * Compare the **empirical** and **theoretical** mean and variance:\n",
        "     $$E[K] = np, \\quad \\mathrm{Var}(K) = np(1-p).$$\n",
        "   * Explain how the distribution shape changes when $p = 0.3$ and $p = 0.7$.\n",
        "   * Relate your findings to the **Law of Large Numbers (LLN)** and **skewness**.\n",
        "\n",
        "3. **Normal approximation with continuity correction (5 pts):**\n",
        "   For $K \\sim \\mathrm{Binomial}(n=20, p=0.5)$, use the Normal approximation\n",
        "   $$K \\approx \\mathcal{N}(np, np(1-p))$$\n",
        "   with a **continuity correction** to estimate and compare:\n",
        "\n",
        "   * $P(8 \\le K \\le 12)$\n",
        "   * $P(K > 15)$\n",
        "   * $P(K < 5)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIeGhvxXnpfB"
      },
      "source": [
        "## Scaffolding Codes (fill the TODOs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2z8Bjm-fWSR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from math import comb\n",
        "\n",
        "np.random.seed(42)  # reproducibility\n",
        "\n",
        "def simulate_game(n=20, p=0.5, players=50_000):\n",
        "    \"\"\"\n",
        "    Simulate the coin toss game.\n",
        "    n = number of tosses per player\n",
        "    p = probability of heads\n",
        "    players = how many players play\n",
        "    Returns: scores (0..n), empirical probabilities\n",
        "    \"\"\"\n",
        "\n",
        "    flips = (np.random.rand(players, n) < p)       # each flip: True=head\n",
        "    counts = flips.sum(axis=1)                     # heads per player\n",
        "    vals, freq = np.unique(counts, return_counts=True)\n",
        "    pmf_emp = np.zeros(n+1, dtype=float)\n",
        "    pmf_emp[vals] = freq / players\n",
        "\n",
        "    return np.arange(n+1), pmf_emp\n",
        "\n",
        "def binomial_theory(n, p):\n",
        "    \"\"\"Theoretical binomial distribution\"\"\"\n",
        "    k_vals = np.arange(n+1)\n",
        "    pmf = np.array([comb(n, k) * (p**k) * (1-p)**(n-k) for k in k_vals], dtype=float)\n",
        "    return k_vals, pmf\n",
        "\n",
        "def plot_game(n=20, p=0.5, players=50_000):\n",
        "    k_emp, pmf_emp = simulate_game(n, p, players)\n",
        "    k_th, pmf_th = binomial_theory(n, p)\n",
        "\n",
        "    plt.figure(figsize=(8,4.8))\n",
        "    plt.bar(k_emp, pmf_emp, alpha=0.6, label=f'Empirical (players={players})')\n",
        "    plt.plot(k_th, pmf_th, marker='o', linewidth=2, label='Theory (Binomial)')\n",
        "    plt.xlabel('Final score (number of heads)')\n",
        "    plt.ylabel('Probability')\n",
        "    plt.title(f'Coin Toss Game: n={n}, p={p}')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_game(n=20, p=0.5, players=50_000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4zccMyP6obt"
      },
      "outputs": [],
      "source": [
        "from math import comb\n",
        "\n",
        "def p_win_binom(n=20, p=0.5, k_min=16):\n",
        "    return sum(comb(n, k) * (p**k) * ((1-p)**(n-k)) for k in range(k_min, n+1))\n",
        "\n",
        "def decide(F, A, pwin):\n",
        "    decision = \"\"\n",
        "    # calculate the profit\n",
        "    expected_profit = (A*pwin)-F\n",
        "\n",
        "    # if profit\n",
        "    if expected_profit > 0:\n",
        "      decision = \"PLAY\"\n",
        "    # if not\n",
        "    else:\n",
        "      decision = \"DON'T PLAY\"\n",
        "\n",
        "    # the decision play/don't play and expected profit value\n",
        "    return decision, expected_profit\n",
        "\n",
        "# main program\n",
        "pwin = p_win_binom(n=20, p=0.5, k_min=16)\n",
        "print(f\"Probability of winning (K > 15 heads): {pwin:.9f}\\n\")\n",
        "\n",
        "print(\"-\" * 65)\n",
        "print(f\"{'Fee (F)':<8} | {'Prize (A)':<10} | {'Expected Profit = (A * P(Win)) - F':<35} | {'Decision':<12}\")\n",
        "print(\"-\" * 65)\n",
        "\n",
        "for F, A in [(1,100), (1,200), (2,100), (2,200)]:\n",
        "    decision, ev = decide(F, A, pwin)\n",
        "    ev_calc_str = f\"({A:<3} * {pwin:.6f}) - {F} = {ev: 7.4f}\"\n",
        "    print(f\"{F:<8} | {A:<10} | {ev_calc_str:<35} | {decision:<12}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "****\n",
        "**TASK 2**\n",
        "\n",
        "* The Binomial (20,0.5) distribution is prefectly symmetric. By looking at the code generated by the code, we can see that the histogram's shape is bell centered exactly at $K = 10$. The probability of getting $k$ heads is the same as the probability of getting $(n-k)$ heads.\n",
        "* **Theoretical:**  \n",
        "Mean $E[K]$ = $np = 20 \\times 0.5 = \\mathbf{10}$  \n",
        "Variance $\\mathrm{Var}(K)$ = $np(1-p)$ = $20 \\times 0.5 \\times 0.5 = 5$  \n",
        "**Empirical vs. Theoretical (LLN):**  \n",
        "The Law of Large Numbers (LLN) states that as the number of experiments (players) increases, the empirical average of the results will converge to the theoretical expected value. With 50,000 players, the empirical mean (the average score of all players) will be extremely close to the theoretical mean of 10. Likewise, the empirical histogram (the \"Empirical\" bars) will very closely match the theoretical \"Binomial\" line plot, meaning their variances will also be nearly identical.\n",
        "* When $p = 0.3$: The distribution is no longer symmetric. Its center (mean) shifts to $np = 20 \\times 0.3 = 6$. Since the outcomes are \"piled up\" on the left side (near 6) and have a long tail extending toward $K=20$, the distribution is positively skewed (or right-skewed).  \n",
        "When $p = 0.7$: The distribution's center shifts to $np = 20 \\times 0.7 = 14$. In this case, the outcomes are \"piled up\" on the right side (near 14) and have a long tail extending toward $K=0$. This is negatively skewed (or left-skewed).\n",
        "\n",
        "\n",
        "****\n",
        "**TASK 3**  \n",
        "* Mean : $\\mu = np = 10$\n",
        "* Variance : $\\sigma^2 = np(1-p) = 5$\n",
        "* Standard Deviation : $\\sigma = \\sqrt{5} \\approx 2.236$  \n",
        "\n",
        "$Z = (X - \\mu) / \\sigma$ and a standard Normal Z-table (where $\\Phi(z)$ is the cumulative probability $P(Z \\le z)$).\n",
        "\n",
        "1. $P(8 \\le K \\le 12)$\n",
        "* Continuity Correction: $P(8-0.5 \\le X \\le 12+0.5)$ = $P(7.5 \\le X \\le 12.5)$\n",
        "* Z-scores:$Z_1 = (7.5 - 10) / 2.236 = -2.5 / 2.236 \\approx -1.118$$Z_2 = (12.5 - 10) / 2.236 = 2.5 / 2.236 \\approx 1.118$\n",
        "* Probability: $P(-1.118 \\le Z \\le 1.118) = \\Phi(1.118) - \\Phi(-1.118) \\approx 0.8682 - 0.1318 = \\mathbf{0.7364}$\n",
        "\n",
        "2. $P(K > 15)$\n",
        "* Continuity Correction: $P(K>15+0.5)$ = $P(K>15.5)$\n",
        "* Z-scores:$Z = (15.5 - 10) / 2.236 = 5.5 / 2.236 \\approx 2.46$\n",
        "* Probability: $P(Z \\ge 2.46) =1-\\Phi(2.46)\\approx 1-0.9931= \\mathbf{0.0069}$\n",
        "\n",
        "3. $P(K < 5)$\n",
        "* Continuity Correction: $P(K<5-0.5)$ = $P(K<4.5)$\n",
        "* Z-scores:$Z = (4.5 - 10) / 2.236 = -5.5 / 2.236 \\approx -2.46$\n",
        "* Probability: $P(Z \\le -2.46) =\\Phi(-2.46)\\approx \\mathbf{0.0069}$\n",
        "****"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUCL5eSH9B51"
      },
      "source": [
        "# 🚪 Problem 2: Many-Door Monty… then the Classic 3 Doors (10 points)\n",
        "\n",
        "You are on a game show with $N$ closed doors. **One door** hides a car; **the rest** hide goats.\n",
        "\n",
        "You pick one door. The host **knows** where the car is. He then **opens every other door except one**, carefully **never** opening the car and **never** opening your chosen door. Now two doors remain closed: **your original door and one other**. Now, you may stay or switch to that other closed door to win the prize (i.e., the car).\n",
        "\n",
        "In this Problem 2, you will explore this for $N=10$, then $N=5$, and finally the classic $N=3$.\n",
        "\n",
        "---\n",
        "\n",
        "## Learning Goals of This Problem\n",
        "\n",
        "* See, by simulation, with $N=\\{10,5,3\\}$ that **switching is almost always better**.\n",
        "* Quantify how much better by **comparing the win rates**.\n",
        "\n",
        "---\n",
        "\n",
        "## Your Tasks (10 points)\n",
        "1. (**4 pts**) Simulation tables (counts, proportions) for $N=\\{10,5,3\\}$.\n",
        "2. (**4 pts**) Bar plots comparing stay vs switch for each $N$.\n",
        "3. (**2 pts**) Short reasoning (2–4 sentences) of why switching almost always better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sF0flZyOIc1v"
      },
      "source": [
        "## Scaffold (student starter; fill TODOs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCkPmW1-Juy4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "def monty_trial_N(N=10, switch=True):\n",
        "    \"\"\"\n",
        "    Simulate ONE round with N doors.\n",
        "    Host knows the car, never opens it, and leaves exactly ONE other door closed.\n",
        "    Return True if the player wins under the chosen strategy.\n",
        "    \"\"\"\n",
        "    # door with car\n",
        "    car_door = np.random.randint(0,N)\n",
        "    # player's pick\n",
        "    player_pick = np.random.randint(0,N)\n",
        "\n",
        "    # if player pick car\n",
        "    if player_pick == car_door:\n",
        "      other_door = np.random.randint(0,N)\n",
        "      while other_door == player_pick:\n",
        "        # the other closed door is not the one that player pick\n",
        "        other_door = np.random.randint(0,N)\n",
        "\n",
        "    # if player pick foat\n",
        "    else:\n",
        "      3 # the other must be car\n",
        "      other_door = car_door\n",
        "\n",
        "    # choosing stategy switching\n",
        "    if switch:\n",
        "      final_pick = other_door\n",
        "\n",
        "    # stay\n",
        "    else:\n",
        "      final_pick = player_pick\n",
        "\n",
        "    # return true if player's final pick is car \n",
        "    return final_pick == car_door\n",
        "\n",
        "# simulate the strategy\n",
        "def simulate_N(N=10, trials=200_000):\n",
        "    \"\"\"\n",
        "    Run 'trials' rounds for both strategies.\n",
        "    Return: wins_stay, p_stay, wins_switch, p_switch\n",
        "    \"\"\"\n",
        "    stay_results = [monty_trial_N(N, switch=False) for _ in range(trials)]\n",
        "    #win rate\n",
        "    wins_stay = np.sum(stay_results)\n",
        "    \n",
        "    switch_results = [monty_trial_N(N, switch=True) for _ in range(trials)]\n",
        "    #win rate\n",
        "    wins_switch = np.sum(switch_results)\n",
        "\n",
        "    # the probabilities\n",
        "    p_stay = wins_stay / trials\n",
        "    p_switch = wins_switch / trials\n",
        "    \n",
        "    return wins_stay, p_stay, wins_switch, p_switch\n",
        "\n",
        "# print report\n",
        "def run_and_report(N, trials=200_000):\n",
        "    wins_stay, p_stay, wins_switch, p_switch = simulate_N(N, trials)\n",
        "    \n",
        "    print(f\"N={N:<2}: STAY   wins={wins_stay:<6}, p={p_stay:<7.5f} | SWITCH wins={wins_switch:<6}, p={p_switch:<7.5f}\")\n",
        "\n",
        "    return p_stay, p_switch\n",
        "\n",
        "# main program\n",
        "N_values = [10, 5, 3]\n",
        "labels = [f'N={n}' for n in N_values]\n",
        "stay_probs = []\n",
        "switch_probs = []\n",
        "\n",
        "#simulating \n",
        "print(\"--- Simulation Results (200,000 trials each) ---\")\n",
        "for N in N_values:\n",
        "    p_stay, p_switch = run_and_report(N, trials=200_000)\n",
        "    stay_probs.append(p_stay)\n",
        "    switch_probs.append(p_switch)\n",
        "print(\"--------------------------------------------------\")\n",
        "\n",
        "stay   = stay_probs\n",
        "switch = switch_probs\n",
        "x = np.arange(len(labels)); w = 0.35\n",
        "\n",
        "# plotting\n",
        "plt.figure(figsize=(7.2,4.5))\n",
        "plt.bar(x - w/2, stay,   width=w, label='Stay')\n",
        "plt.bar(x + w/2, switch, width=w, label='Switch')\n",
        "\n",
        "plt.ylim(0, 1.05)\n",
        "plt.axhline(y=0.5, color='gray', linestyle='--', linewidth=0.8)\n",
        "plt.xticks(x, labels)\n",
        "plt.ylabel('Win rate (proportion)')\n",
        "plt.title('Monty Hall with N doors: Stay vs Switch')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "\n",
        "for i in range(len(labels)):\n",
        "    plt.text(x[i] - w/2, stay[i] + 0.01, f'{stay[i]:.3f}', ha='center', va='bottom', fontsize=9)\n",
        "    plt.text(x[i] + w/2, switch[i] + 0.01, f'{switch[i]:.3f}', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The **Stay Strategy** wins only if you pick a door with car in it, which has a probability of $1/N$ and if the host open the other doors, it doesn't change the probability. The **Switch Strategy** wins only if you pick a door with goat in it, which has a probability of $(N-1)/N$ and if you pick it, the host will open all other doors with goat in it, leaving only the door with a car in it as the only other door to switch to. In conclusion, **Switching** concentrates THE $(N-1)/N$ probability onto that one remaining choice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRt8dx2dSixz"
      },
      "source": [
        "# 🂡 Problem 3: Mystery Deck (10 points)\n",
        "\n",
        "At the Magic Club, the host secretly chooses one of two decks with equal chance:\n",
        "\n",
        "1. Standard deck (S): 26 red, 26 black\n",
        "2. Crimson deck (C): 32 red, 20 black\n",
        "\n",
        "You open cards **one by one (without replacement)** and only see the **color** (Red/Black). After each $n$-th draw (i.e, $n=0,...,52$), you must update the posterior $P(C|n)$ where $P(C)=0.5$.\n",
        "\n",
        "Show how the posterior changes from **before the first card** (i.e, draw $n=0$) to **after all cards** (i.e, $n=52$) by plotting $P(C|n)$ for $n=0,...,52$.\n",
        "\n",
        "---\n",
        "\n",
        "## Goals of Learning: Hypergeometric Random Variable\n",
        "\n",
        "After draw $n$, let $r$ be the number of reds and $b=n-r$ the number of blacks observed. Then, the likelihood under a deck with $R$ reds and $B$ blacks is hypergeometric:\n",
        "\n",
        "$\\mathcal{L}(r,b \\mid R,B)\n",
        "= \\frac{\\binom{R}{r}\\,\\binom{B}{b}}{\\binom{R+B}{\\,r+b\\,}}.$\n",
        "\n",
        "---\n",
        "\n",
        "## Your Tasks\n",
        "\n",
        "1. (8 pts) A line plot of $P(C|$data up to draw $n)$ for $n=0,...,52$.\n",
        "2. (2 pts) What is the earlieast draw to know which deck you have?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSuY6TkMyW8C"
      },
      "source": [
        "## Student scaffold (with TODOs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sx3M77xTyZ4p"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from math import comb\n",
        "np.random.seed(42)\n",
        "\n",
        "# --- Deck definitions ---\n",
        "N = 52\n",
        "R_S, B_S = 26, 26    # Standard\n",
        "R_C, B_C = 32, 20    # Crimson\n",
        "prior_C = 0.5\n",
        "\n",
        "# --- Choose a true deck for this run (set to \"C\" or \"S\") ---\n",
        "true_deck = \"C\"  # Change to \"S\" to test the other case.\n",
        "\n",
        "# --- Build and shuffle the true deck (list of \"R\"/\"B\") ---\n",
        "def build_deck(true_deck=\"C\", seed=7):\n",
        "    if true_deck not in (\"C\",\"S\"):\n",
        "        raise ValueError(\"true_deck must be 'C' or 'S'\")\n",
        "    # TODO: construct the deck list with the correct counts; then shuffle with RNG.\n",
        "    rng = np.random.default_rng(seed)\n",
        "    rng.shuffle(deck)\n",
        "    return deck\n",
        "\n",
        "# --- Hypergeometric log-likelihood helper ---\n",
        "def log_hypergeom_likelihood(R, B, r, b):\n",
        "    \"\"\"\n",
        "    log P(see r reds and b blacks in n=r+b draws without replacement | R,B in deck)\n",
        "    \"\"\"\n",
        "    n = r + b\n",
        "    # TODO: log likelihood of the hypergeometric random variables\n",
        "    return 0.0\n",
        "\n",
        "# --- Posterior updater using Bayes in log-space for stability ---\n",
        "def posterior_C_after(r, b, prior=prior_C):\n",
        "    \"\"\"\n",
        "    Return P(C | r reds, b blacks) with prior P(C)=prior.\n",
        "    \"\"\"\n",
        "    # TODO: compute log-likelihoods under C and S\n",
        "    # TODO: combine with log-prior, normalize safely, and return posterior for C\n",
        "    return 0.5\n",
        "\n",
        "# --- Run the single reveal sequence; record posterior after each draw ---\n",
        "r = b = 0\n",
        "posteriors = [prior_C]   # include n=0\n",
        "draw_idx   = [0]\n",
        "# TODO: iterate over the 52 cards, update r/b, compute posterior, append to lists\n",
        "\n",
        "# --- Plot posterior vs draw index (0..52) ---\n",
        "plt.figure(figsize=(7,4))\n",
        "# TODO: plot draw_idx vs posteriors as a line with markers\n",
        "plt.xlabel(\"Draw number (n)\")\n",
        "plt.ylabel(\"Posterior  P(Crimson | data up to n)\")\n",
        "plt.title(\"Sequential Bayes: posterior over time\")\n",
        "plt.ylim(0,1)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- Print the final counts and posterior ---\n",
        "# print(f\"Final r={r}, b={b}, posterior P(C|all)={posteriors[-1]:.6f}\")\n",
        "# Explain briefly: each step used a hypergeometric likelihood."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuDGqjhu5-is"
      },
      "source": [
        "\n",
        "# 🎲 Problem 4: The Sum and Difference of Two Dice (15 points)\n",
        "\n",
        "In a new tabletop experiment, a player rolls **two independent dice** at once:\n",
        "\n",
        "* **Die A:** a **6-sided** die with faces 1–6.\n",
        "* **Die B:** an **8-sided** die with faces 1–8.\n",
        "\n",
        "Each roll records two random variables:\n",
        "\n",
        "* (S = A + B)  (the **sum** of the two dice)\n",
        "* (D = |A - B|)  (the **absolute difference** between them)\n",
        "\n",
        "The designer wants to understand how these two outcomes behave jointly.\n",
        "\n",
        "---\n",
        "\n",
        "## Tasks\n",
        "\n",
        "1. **(7 pts) Simulate the joint PMF.**\n",
        "   Roll both dice 10 000 times and build the **empirical joint probability table** (P(S,D)).\n",
        "   Present it either as a matrix or DataFrame whose rows = values of (S), columns = values of (D).\n",
        "\n",
        "2. **(2 pts) Find the marginals.**\n",
        "   Compute\n",
        "   $$\n",
        "   P_S(s)=\\sum_d P(S=s,D=d),\\qquad\n",
        "   P_D(d)=\\sum_s P(S=s,D=d).\n",
        "   $$\n",
        "\n",
        "3. **(4 pts) Moments.**\n",
        "   Estimate\n",
        "   $$\n",
        "   E[S],;E[D],;\\mathrm{Var}(S),;\\mathrm{Var}(D),;\\mathrm{Cov}(S,D),;\\mathrm{Corr}(S,D).\n",
        "   $$\n",
        "\n",
        "4. **(2 pts) Analysis.**\n",
        "   Answer briefly:\n",
        "\n",
        "   * Why are some ((S,D)) pairs impossible (i.e., have (P(S,D)=0))?\n",
        "   * Does knowing (S) give information about (D)? Are they independent? Explain using intuition or your simulation table.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZ8jXEUyf1IJ"
      },
      "source": [
        "## Starter Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztvbyhzAf2io"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "N = 10_000\n",
        "rng = np.random.default_rng(42)\n",
        "\n",
        "# --- Step 1: Simulate the two dice ---\n",
        "A = rng.integers(1, 7, size=N)     # 6-sided\n",
        "B = rng.integers(1, 9, size=N)     # 8-sided\n",
        "\n",
        "# --- Step 2: Define random variables ---\n",
        "S = A + B          # Sum\n",
        "D = np.abs(A - B)  # Absolute difference\n",
        "\n",
        "# TODO 1: Build joint frequency table of (S,D)\n",
        "# df = pd.DataFrame(...)\n",
        "# joint_counts = ...\n",
        "# joint_pmf = ...\n",
        "\n",
        "# TODO 2: Compute marginals P_S and P_D\n",
        "\n",
        "# TODO 3: Estimate E[S], E[D], Var(S), Var(D), Cov(S,D), Corr(S,D)\n",
        "\n",
        "# TODO 4: Write your analysis in a Markdown cell\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fw-AgX_yDyH"
      },
      "source": [
        "# 🐞Problem 5: Finding errors in a piece of software (20 Point)\n",
        "\n",
        "One good brief intro about Monte Carlo methods is as follows (taken from Baron, 2019).\n",
        "> Computer simulations refer to a regeneration of a process by writing a suitable computer\n",
        "program and observing its results. Monte Carlo methods are those based on computer\n",
        "simulations involving random numbers.\n",
        "> The main purpose of simulations is estimating such quantities whose direct computation is\n",
        "complicated, risky, consuming, expensive, or impossible. For example, suppose a complex\n",
        "device or machine is to be built and launched. Before it happens, its performance is\n",
        "simulated, and this allows experts to evaluate its adequacy and associated risks carefully and\n",
        "safely. For example, one surely prefers to evaluate reliability and safety of a new module of\n",
        "a space station by means of computer simulations rather than during the actual mission.\n",
        "> Monte Carlo methods are mostly used for the computation of probabilities, expected values,\n",
        "and other distribution characteristics. Recall that probability can be deﬁned as a long-run\n",
        "proportion. With the help of random number generators, computers can actually simulate\n",
        "a long run. Then, probability can be estimated by a mere computation of the associated\n",
        "observed frequency. The longer run is simulated, the more accurate result is obtained.\n",
        "Similarly, one can estimate expectations, variances, and other distribution characteristics\n",
        "from a long run of simulated random variables.\n",
        "\n",
        "Every day, software developers ﬁnd a random number of errors and correct them.\n",
        "The number of errors $X_t$ found on day $t$ is modeled by a Poisson($\\lambda_t$) distribution\n",
        "whose parameter is the smallest number of errors found during the previous 3 days.\n",
        "That is,\n",
        "$$\\lambda_t = min( X_{t-1} , X_{t - 2} , X_{t - 3}).$$\n",
        "Suppose that during the ﬁrst three days, software developers ﬁnd 28, 22, and 18 errors.\n",
        "\n",
        "1. Predict the time it will take to ﬁnd all the errors.\n",
        "2. Estimate the probability that some errors will remain undetected after 21 days.\n",
        "3. Predict the total number of errors in this new release.\n",
        "\n",
        "### Target Output\n",
        "1. The expected time to detect all the errors is about 19.7 days,\n",
        "2. The probability that errors remain after 21 days is about 0.34,\n",
        "3. The total number of errors is about 222 errors overall.\n",
        "\n",
        "### Your task\n",
        "Write Python code to reproduce the target output above.\n",
        "Do not hardcode any result.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bo-qJbY0obMC"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'numpy'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      4\u001b[39m SIMULATION_LENGTH:\u001b[38;5;28mint\u001b[39m = \u001b[32m1000\u001b[39m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "SIMULATION_LENGTH:int = 1000\n",
        "TOTAL_SIMULATION:int = 500\n",
        "DAYS_CHECKED:int = 21\n",
        "\n",
        "init_errors_found = [28, 22, 18]\n",
        "init_poisson_lambda = min(init_errors_found)\n",
        "poisson_lambda = init_poisson_lambda\n",
        "days_stats:list[int] = [] # A list of the days needed to find all errors in indexed-i simulation\n",
        "errors_stats:list[int] = init_errors_found # A list of errors found on indexed-i day in all simulation\n",
        "after_day_count = 0\n",
        "\n",
        "for _ in range(TOTAL_SIMULATION):\n",
        "    poisson_lambda = init_poisson_lambda\n",
        "    for day in range(4, SIMULATION_LENGTH):\n",
        "        nday_errors = np.random.Generator.poisson(poisson_lambda) \n",
        "        if nday_errors == 0: # Errors not found, assume all errors has been found\n",
        "            days_stats.append(day + 3)\n",
        "            if day > DAYS_CHECKED:\n",
        "                after_day_count += 1\n",
        "            break\n",
        "        poisson_lambda = min(nday_errors, poisson_lambda)\n",
        "        errors_stats.append(nday_errors)\n",
        "\n",
        "expected_days = np.average(days_stats)\n",
        "prob:float = 1.00 * after_day_count / len(days_stats) \n",
        "expected_errors = np.average(errors_stats)\n",
        "# Prints outputs\n",
        "print(f\"1. The expected time to detect all errors is about { expected_days } days,\")\n",
        "print(f\"2. The probability that errors remain after { DAYS_CHECKED } days is about { prob:.1f }\")\n",
        "print(f\"3. The total amount of errors is about { expected_errors } errors overall.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
